{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shear modulus G (MPa): 1.9999e+04\n",
      "Identified Young's moduli (MPa): 5.201e+04 ; 5.202e+04 ; 5.186e+04\n",
      "Identified Poisson's ratios: 3.004e-01 ; 3.005e-01 ; 2.965e-01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load the data\n",
    "data = loadmat('Iosipescu_isotropic.mat')\n",
    "X1 = data['X1']\n",
    "X2 = data['X2']\n",
    "L = data['L'].item()\n",
    "w = data['w'].item()\n",
    "t = data['t'].item()\n",
    "F = data['F'].item()\n",
    "Eps1 = data['Eps1']\n",
    "Eps2 = data['Eps2']\n",
    "Eps6 = data['Eps6']\n",
    "\n",
    "# Units in N and mm → MPa for stiffness\n",
    "# Direct identification of shear modulus\n",
    "G = F / (w * t * np.mean(Eps6))\n",
    "\n",
    "# I: First set of virtual fields\n",
    "A = np.zeros((2, 2))\n",
    "B = np.zeros(2)\n",
    "\n",
    "# First virtual field\n",
    "A[0, 0] = np.mean(Eps6)\n",
    "A[0, 1] = -np.mean(Eps6)\n",
    "B[0] = 2 * F / (w * t)\n",
    "\n",
    "# Second virtual field\n",
    "A[1, 0] = -np.mean(Eps1 * (L - 2 * X1) * X2)\n",
    "A[1, 1] = -np.mean(Eps2 * (L - 2 * X1) * X2)\n",
    "B[1] = F * L**2 / (6 * w * t)\n",
    "\n",
    "Q = np.linalg.inv(A) @ B\n",
    "Nu = [Q[1] / Q[0]]\n",
    "E = [Q[0] * (1 - Nu[0]**2)]\n",
    "\n",
    "# II: Second set of virtual fields\n",
    "AA = np.zeros((2, 2))\n",
    "BB = np.zeros(2)\n",
    "\n",
    "# First virtual field\n",
    "AA[0, 0] = np.mean(Eps6)\n",
    "AA[0, 1] = -np.mean(Eps6)\n",
    "BB[0] = 2 * F / (w * t)\n",
    "\n",
    "# Second virtual field\n",
    "AA[1, 0] = -np.mean(Eps1 * (L - 2 * X1) * X2) - 0.5 * np.mean(Eps6 * X1 * (L - X1))\n",
    "AA[1, 1] = -np.mean(Eps2 * (L - 2 * X1) * X2) + 0.5 * np.mean(Eps6 * X1 * (L - X1))\n",
    "BB[1] = 0\n",
    "\n",
    "QQ = np.linalg.inv(AA) @ BB\n",
    "Nu.append(QQ[1] / QQ[0])\n",
    "E.append(QQ[0] * (1 - Nu[1]**2))\n",
    "\n",
    "# III: Third set of virtual fields\n",
    "AAA = np.zeros((2, 2))\n",
    "BBB = np.zeros(2)\n",
    "\n",
    "# First virtual field\n",
    "AAA[0, 0] = np.mean(Eps6)\n",
    "AAA[0, 1] = -np.mean(Eps6)\n",
    "BBB[0] = 2 * F / (w * t)\n",
    "\n",
    "# Second virtual field\n",
    "AAA[1, 0] = -np.mean(Eps2 * X1 * (L - X1)) - 0.5 * np.mean(Eps6 * (L - 2 * X1) * X2)\n",
    "AAA[1, 1] = -np.mean(Eps1 * X1 * (L - X1)) + 0.5 * np.mean(Eps6 * (L - 2 * X1) * X2)\n",
    "BBB[1] = 0\n",
    "\n",
    "QQQ = np.linalg.inv(AAA) @ BBB\n",
    "Nu.append(QQQ[1] / QQQ[0])\n",
    "E.append(QQQ[0] * (1 - Nu[2]**2))\n",
    "\n",
    "# Output\n",
    "\n",
    "print(\"Shear modulus G (MPa):\", \"{:.4e}\".format(G))\n",
    "print(\"Identified Young's moduli (MPa):\", \" ; \".join(\"{:.3e}\".format(e) for e in E))\n",
    "print(\"Identified Poisson's ratios:\", \" ; \".join(\"{:.3e}\".format(nu) for nu in Nu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Load FEM Data and Build Interpolation Functions\n",
    "# =============================================================================\n",
    "dir_path = \"..\"\n",
    "FEM_dataset = \"100x100mm.dat\"\n",
    "L_max = 100.0\n",
    "\n",
    "fem_file = os.path.join(dir_path, r\"data_fem\", FEM_dataset)\n",
    "data = np.loadtxt(fem_file)\n",
    "X_val      = data[:, :2]\n",
    "u_val      = data[:, 2:4]\n",
    "strain_val = data[:, 4:7]\n",
    "stress_val = data[:, 7:10]\n",
    "solution_val = np.hstack((u_val, stress_val))\n",
    "\n",
    "n_mesh_points = int(np.sqrt(X_val.shape[0]))\n",
    "x_grid = np.linspace(0, L_max, n_mesh_points)\n",
    "y_grid = np.linspace(0, L_max, n_mesh_points)\n",
    "\n",
    "def create_interpolation_fn(data_array):\n",
    "    num_components = data_array.shape[1]\n",
    "    interpolators = []\n",
    "    for i in range(num_components):\n",
    "        interp = RegularGridInterpolator(\n",
    "            (x_grid, y_grid),\n",
    "            data_array[:, i].reshape(n_mesh_points, n_mesh_points).T,\n",
    "        )\n",
    "        interpolators.append(interp)\n",
    "    def interpolation_fn(x):\n",
    "        return np.array([interp((x[:, 0], x[:, 1])) for interp in interpolators]).T\n",
    "    return interpolation_fn\n",
    "\n",
    "solution_fn = create_interpolation_fn(solution_val)\n",
    "strain_fn   = create_interpolation_fn(strain_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dir_path = \"..\"\n",
    "\n",
    "# --- 1) Adding Gaussian noise to the data ---\n",
    "noise_level = 1e-4\n",
    "Eps1 += np.random.normal(0, noise_level, Eps1.shape)\n",
    "Eps2 += np.random.normal(0, noise_level, Eps2.shape)\n",
    "Eps6 += np.random.normal(0, noise_level, Eps6.shape)\n",
    "\n",
    "# --- 2) Problem parameters from your FEniCS code ---\n",
    "L = 100.0   # mm\n",
    "m = 0.3     # N/mm (side‐loading slope)\n",
    "b = 50.0    # N (side‐loading intercept)\n",
    "\n",
    "# --- 3) Compute total shear load on the right boundary ---\n",
    "#    ∫[0→L] (m y + b) dy = m L^2/2 + b L\n",
    "F = m*L**2/2 + b*L\n",
    "\n",
    "def calc_parameters(Eps1, Eps2, Eps6):\n",
    "        \"\"\"\n",
    "        Calculate the E and ν parameters from the strain data.\n",
    "        \"\"\"\n",
    "        # build A and B\n",
    "        A = np.zeros((2, 2))\n",
    "        B = np.zeros(2)\n",
    "\n",
    "        # Virtual field 1:  u1*=0, u2*=-x2  ⇒ ε1*=0, ε2*=-1\n",
    "        A[0, 0] = np.mean(Eps2)*L**2     \n",
    "        A[0, 1] = np.mean(Eps1)*L**2      \n",
    "        B[0]    = 0        \n",
    "\n",
    "        # Virtual field 2:  u1*=x1, u2*=0  ⇒ ε1*=1, ε2*=0\n",
    "        A[1, 0] = np.mean(Eps1)*L**2       # ∑ ε₁ sᵢ\n",
    "        A[1, 1] = np.mean(Eps2)*L**2      # ∑ ε₂ sᵢ\n",
    "        B[1]    = F * L                # ∑ σ₁ lᵢ\n",
    "\n",
    "        # solve for Q = [Q11, Q12]\n",
    "        Q11, Q12 = np.linalg.solve(A, B)\n",
    "\n",
    "        # retrieve E and ν\n",
    "        μ_id = (Q11 - Q12)/2\n",
    "        λ_id = Q12\n",
    "        Nu  = λ_id / (2*(μ_id + λ_id))\n",
    "        E  = μ_id*(3*λ_id + 2*μ_id)/(λ_id + μ_id)\n",
    "        return E, Nu\n",
    "\n",
    "def load_data(DIC_dataset_path, DIC_dataset_number, L_max, strain_fn, num_measurments, noise_magnitude, DIC_region=[0,0,L_max,L_max]):\n",
    "    \"\"\"\n",
    "    Load the DIC data from the specified path.\n",
    "    \"\"\"\n",
    "    if DIC_dataset_path != \"no_dataset\":\n",
    "        dic_path = os.path.join(dir_path, DIC_dataset_path)\n",
    "        dic_number = DIC_dataset_number\n",
    "        X_dic = pd.read_csv(os.path.join(dic_path, \"x\", f\"x_{dic_number}.csv\"), delimiter=\";\").dropna(axis=1).to_numpy()\n",
    "        Y_dic = pd.read_csv(os.path.join(dic_path, \"y\", f\"y_{dic_number}.csv\"), delimiter=\";\").dropna(axis=1).to_numpy()\n",
    "        Ux_dic = pd.read_csv(os.path.join(dic_path, \"ux\", f\"ux_{dic_number}.csv\"), delimiter=\";\").dropna(axis=1).to_numpy().T.reshape(-1, 1)\n",
    "        Uy_dic = pd.read_csv(os.path.join(dic_path, \"uy\", f\"uy_{dic_number}.csv\"), delimiter=\";\").dropna(axis=1).to_numpy().T.reshape(-1, 1)\n",
    "        E_xx_dic = pd.read_csv(os.path.join(dic_path, \"exx\", f\"exx_{dic_number}.csv\"), delimiter=\";\").dropna(axis=1).to_numpy().T.reshape(-1, 1)\n",
    "        E_yy_dic = pd.read_csv(os.path.join(dic_path, \"eyy\", f\"eyy_{dic_number}.csv\"), delimiter=\";\").dropna(axis=1).to_numpy().T.reshape(-1, 1)\n",
    "        E_xy_dic = pd.read_csv(os.path.join(dic_path, \"exy\", f\"exy_{dic_number}.csv\"), delimiter=\";\").dropna(axis=1).to_numpy().T.reshape(-1, 1)\n",
    "        \n",
    "        region_mask = np.logical_and(\n",
    "            np.logical_and(X_dic >= DIC_region[0], X_dic <= DIC_region[2]),\n",
    "            np.logical_and(Y_dic >= DIC_region[1], Y_dic <= DIC_region[3])\n",
    "        )\n",
    "        X_dic = X_dic[region_mask]\n",
    "        Y_dic = Y_dic[region_mask]\n",
    "        E_xx_dic = E_xx_dic[region_mask.T.reshape(-1,1)]\n",
    "        E_yy_dic = E_yy_dic[region_mask.T.reshape(-1,1)]\n",
    "        E_xy_dic = E_xy_dic[region_mask.T.reshape(-1,1)]\n",
    "        X_DIC_input = np.hstack([X_dic, Y_dic])\n",
    "        DIC_data = np.stack([E_xx_dic, E_yy_dic, E_xy_dic], axis=-1)\n",
    "    else:\n",
    "        X_DIC_input = [np.linspace(DIC_region[0], DIC_region[2], num_measurments),\n",
    "                       np.linspace(DIC_region[1], DIC_region[3], num_measurments)]\n",
    "        X_DIC_input = np.meshgrid(*X_DIC_input)\n",
    "        X_DIC_input = np.stack([x.ravel() for x in X_DIC_input], axis=-1) \n",
    "        DIC_data = strain_fn(X_DIC_input)\n",
    "        DIC_data += np.random.normal(0, noise_magnitude, DIC_data.shape)\n",
    "    return X_DIC_input, DIC_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified:  E = 209.1031 GPa,   ν = 0.3015\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prop = 0\n",
    "DIC_region = [prop*L, prop*L, (1-prop)*L, (1-prop)*L]\n",
    "X_DIC_input, DIC_data = load_data(\"no_dataset\", 0, L, strain_fn, 10, 1e-6, DIC_region=DIC_region)\n",
    "Eps1 = DIC_data[:, 0].reshape(-1, 1)\n",
    "Eps2 = DIC_data[:, 1].reshape(-1, 1)\n",
    "Eps6 = DIC_data[:, 2].reshape(-1, 1)\n",
    "\n",
    "E, Nu = calc_parameters(Eps1, Eps2, Eps6)\n",
    "print(f\"Identified:  E = {E/1e3:.4f} GPa,   ν = {Nu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified (mean +/- std):  E = 210.2148 ± 0.0885 GPa,   ν = 0.2989 ± 0.0002\n"
     ]
    }
   ],
   "source": [
    "camera_resolution = \"2MP\"\n",
    "DIC_dataset_path = f\"2_noise_study/data_dic/{camera_resolution}/1noise\"\n",
    "prop = 0\n",
    "DIC_region = [prop*L, prop*L, (1-prop)*L, (1-prop)*L]\n",
    "\n",
    "E_list = []\n",
    "Nu_list = []\n",
    "for dic_number in range(1, 11):\n",
    "    X_DIC_input, DIC_data = load_data(DIC_dataset_path, dic_number, L, strain_fn, 4, 1e-6, DIC_region=DIC_region)\n",
    "    Eps1 = DIC_data[:, 0].reshape(-1, 1)\n",
    "    Eps2 = DIC_data[:, 1].reshape(-1, 1)\n",
    "    Eps6 = DIC_data[:, 2].reshape(-1, 1)\n",
    "\n",
    "    E, Nu = calc_parameters(Eps1, Eps2, Eps6)\n",
    "    E_list.append(E)\n",
    "    Nu_list.append(Nu)\n",
    "\n",
    "E_list = np.array(E_list)\n",
    "Nu_list = np.array(Nu_list)\n",
    "\n",
    "print(f\"Identified (mean +/- std):  E = {np.mean(E_list)/1e3:.4f} ± {np.std(E_list)/1e3:.4f} GPa,   ν = {np.mean(Nu_list):.4f} ± {np.std(Nu_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Assuming load_data and calc_parameters are defined elsewhere\n",
    "# Define your variables and functions here\n",
    "\n",
    "resolutions = [\"5MP\", \"2MP\", \"0.4MP\"]\n",
    "prop = 0\n",
    "precision = 4 \n",
    "\n",
    "# Initialize lists to store VFM results for each resolution\n",
    "E_VFM_means = []\n",
    "E_VFM_stds = []\n",
    "Nu_VFM_means = []\n",
    "Nu_VFM_stds = []\n",
    "\n",
    "for camera_resolution in resolutions:\n",
    "    DIC_dataset_path = f\"2_noise_study/data_dic/{camera_resolution}/1noise\"\n",
    "    DIC_region = [prop*L, prop*L, (1-prop)*L, (1-prop)*L]\n",
    "\n",
    "    E_list = []\n",
    "    Nu_list = []\n",
    "    for dic_number in range(1, 11):\n",
    "        X_DIC_input, DIC_data = load_data(DIC_dataset_path, dic_number, L, strain_fn, 4, 1e-6, DIC_region=DIC_region)\n",
    "        Eps1 = DIC_data[:, 0].reshape(-1, 1)\n",
    "        Eps2 = DIC_data[:, 1].reshape(-1, 1)\n",
    "        Eps6 = DIC_data[:, 2].reshape(-1, 1)\n",
    "\n",
    "        E, Nu = calc_parameters(Eps1, Eps2, Eps6)\n",
    "        E_list.append(E)\n",
    "        Nu_list.append(Nu)\n",
    "\n",
    "    E_list = np.array(E_list)\n",
    "    Nu_list = np.array(Nu_list)\n",
    "\n",
    "    # Calculate mean and std for E and Nu\n",
    "    E_mean = np.mean(E_list) / 1e3\n",
    "    E_std = np.std(E_list) / 1e3\n",
    "    Nu_mean = np.mean(Nu_list)\n",
    "    Nu_std = np.std(Nu_list)\n",
    "\n",
    "    # Append the results to the lists\n",
    "    E_VFM_means.append(round(E_mean, precision))\n",
    "    E_VFM_stds.append(round(E_std, precision))\n",
    "    Nu_VFM_means.append(round(Nu_mean, precision))\n",
    "    Nu_VFM_stds.append(round(Nu_std, precision))\n",
    "\n",
    "# Load the existing JSON file\n",
    "with open(\"../2_noise_study/results/summary.json\", 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Append the VFM field to the JSON structure for each resolution\n",
    "json_data[\"E\"][\"VFM\"] = {\"mean\": E_VFM_means, \"std\": E_VFM_stds}\n",
    "json_data[\"nu\"][\"VFM\"] = {\"mean\": Nu_VFM_means, \"std\": Nu_VFM_stds}\n",
    "\n",
    "# Save the updated JSON structure back to the file\n",
    "with open(\"../2_noise_study/results/summary.json\", 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
