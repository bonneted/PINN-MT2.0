{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Load FEM Data and Build Interpolation Functions\n",
    "# =============================================================================\n",
    "dir_path = \"..\"\n",
    "FEM_dataset = \"100x100mm.dat\"\n",
    "L_max = 100.0\n",
    "\n",
    "fem_file = os.path.join(dir_path, r\"data_fem\", FEM_dataset)\n",
    "data = np.loadtxt(fem_file)\n",
    "X_val      = data[:, :2]\n",
    "u_val      = data[:, 2:4]\n",
    "strain_val = data[:, 4:7]\n",
    "stress_val = data[:, 7:10]\n",
    "solution_val = np.hstack((u_val, stress_val))\n",
    "\n",
    "n_mesh_points = int(np.sqrt(X_val.shape[0]))\n",
    "x_grid = np.linspace(0, L_max, n_mesh_points)\n",
    "y_grid = np.linspace(0, L_max, n_mesh_points)\n",
    "\n",
    "def create_interpolation_fn(data_array):\n",
    "    num_components = data_array.shape[1]\n",
    "    interpolators = []\n",
    "    for i in range(num_components):\n",
    "        interp = RegularGridInterpolator(\n",
    "            (x_grid, y_grid),\n",
    "            data_array[:, i].reshape(n_mesh_points, n_mesh_points).T,\n",
    "        )\n",
    "        interpolators.append(interp)\n",
    "    def interpolation_fn(x):\n",
    "        return np.array([interp((x[:, 0], x[:, 1])) for interp in interpolators]).T\n",
    "    return interpolation_fn\n",
    "\n",
    "solution_fn = create_interpolation_fn(solution_val)\n",
    "strain_fn   = create_interpolation_fn(strain_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def load_data(\n",
    "    DIC_dataset_path,\n",
    "    DIC_dataset_number,\n",
    "    strain_fn,\n",
    "    num_measurments,\n",
    "    noise_magnitude,\n",
    "    DIC_region,\n",
    "    pad_extrapolate=False,\n",
    "    dir_path='..',\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load DIC data (or synthetic), subsample uniformly over full_region to\n",
    "    num_measurments^2 points, then apply DIC_region mask.\n",
    "    If pad_extrapolate, out-of-region strains are replaced by nearest in-region.\n",
    "    Prints grid sizes as Full: n_f x n_f --> Region: n_r1 x n_r2 (or keeps Full with padding).\n",
    "    \"\"\"\n",
    "    if DIC_dataset_path != 'no_dataset':\n",
    "        base = os.path.join(dir_path, DIC_dataset_path)\n",
    "        n = DIC_dataset_number\n",
    "        Xg = pd.read_csv(os.path.join(base, 'x', f'x_{n}.csv'), delimiter=';').dropna(axis=1).to_numpy()\n",
    "        Yg = pd.read_csv(os.path.join(base, 'y', f'y_{n}.csv'), delimiter=';').dropna(axis=1).to_numpy()\n",
    "        Exx = pd.read_csv(os.path.join(base, 'exx', f'exx_{n}.csv'), delimiter=';').dropna(axis=1).to_numpy()\n",
    "        Eyy = pd.read_csv(os.path.join(base, 'eyy', f'eyy_{n}.csv'), delimiter=';').dropna(axis=1).to_numpy()\n",
    "        Exy = pd.read_csv(os.path.join(base, 'exy', f'exy_{n}.csv'), delimiter=';').dropna(axis=1).to_numpy()\n",
    "        coords, data = postprocess_dic_data(\n",
    "            Xg, Yg, Exx, Eyy, Exy,\n",
    "            DIC_region=DIC_region,\n",
    "            num_measurments=num_measurments,\n",
    "            pad_extrapolate=pad_extrapolate,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "    else:\n",
    "        xmin, ymin, xmax, ymax = DIC_region\n",
    "        xs = np.linspace(xmin, xmax, num_measurments)\n",
    "        ys = np.linspace(ymin, ymax, num_measurments)\n",
    "        Xg, Yg = np.meshgrid(xs, ys)\n",
    "        coords = np.column_stack([Xg.ravel(), Yg.ravel()])\n",
    "        data = strain_fn(coords)\n",
    "        data += np.random.normal(0, noise_magnitude, data.shape)\n",
    "        if verbose:\n",
    "            print(f\"Dic grid: {num_measurments} x {num_measurments} with {noise_magnitude} magnitude noise\")\n",
    "    return coords, data\n",
    "\n",
    "\n",
    "def postprocess_dic_data(\n",
    "    Xg, Yg, Exx, Eyy, Exy,\n",
    "    DIC_region,\n",
    "    num_measurments,\n",
    "    pad_extrapolate=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    # Subsample full grid uniformly by index\n",
    "    m, n = Xg.shape\n",
    "    i_full = np.round(np.linspace(0, m-1, min(m, num_measurments))).astype(int)\n",
    "    j_full = np.round(np.linspace(0, n-1, min(n, num_measurments))).astype(int)\n",
    "    n_f = i_full.size\n",
    "    # Extract subsampled coords and values\n",
    "    sel_full = np.ix_(i_full, j_full)\n",
    "    Xf = Xg[sel_full]; Yf = Yg[sel_full]\n",
    "    Exx_f = Exx[sel_full]; Eyy_f = Eyy[sel_full]; Exy_f = Exy[sel_full]\n",
    "    # Region mask on subsampled grid\n",
    "    xmin, ymin, xmax, ymax = DIC_region\n",
    "    mask = (Xf>=xmin)&(Xf<=xmax)&(Yf>=ymin)&(Yf<=ymax)\n",
    "    # Count region rows/cols\n",
    "    rows_r, cols_r = np.unique(np.where(mask)[0]), np.unique(np.where(mask)[1])\n",
    "    # Print sizes\n",
    "    if verbose:\n",
    "        if pad_extrapolate:\n",
    "            print(f\"DIC grid: {m} x {n} --> Subsampled grid (including padding): {n_f} x {n_f} --> Region grid: {rows_r.size} x {cols_r.size}\")\n",
    "        else:\n",
    "            print(f\"DIC grid: {m} x {n} --> Subsampled grid: {n_f} x {n_f} --> Region grid (points used): {rows_r.size} x {cols_r.size}\")\n",
    "    # Apply mask or padding\n",
    "    if pad_extrapolate:\n",
    "        # build in-region tree\n",
    "        pts_in = np.column_stack([Xf[mask].ravel(), Yf[mask].ravel()])\n",
    "        vals_in = np.column_stack([Exx_f[mask].ravel(), Eyy_f[mask].ravel(), Exy_f[mask].ravel()])\n",
    "        tree = cKDTree(pts_in)\n",
    "        pts_all = np.column_stack([Xf.ravel(), Yf.ravel()])\n",
    "        _, idx = tree.query(pts_all)\n",
    "        filled = vals_in[idx]\n",
    "        coords = pts_all\n",
    "        data = filled\n",
    "    else:\n",
    "        coords = np.column_stack([Xf[mask].ravel(), Yf[mask].ravel()])\n",
    "        data = np.column_stack([Exx_f[mask].ravel(), Eyy_f[mask].ravel(), Exy_f[mask].ravel()])\n",
    "    return coords, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dic grid: 4 x 4 with 1e-06 magnitude noise\n",
      "Identified:  E = 207.0592 ± 0.1316 GPa, ν = 0.3051 ± 0.0005\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"..\"\n",
    "\n",
    "# --- 2) Problem parameters from your FEniCS code ---\n",
    "L = 100.0   # mm\n",
    "m = 0.3     # N/mm (side‐loading slope)\n",
    "b = 50.0    # N (side‐loading intercept)\n",
    "\n",
    "# --- 3) Compute total shear load on the right boundary ---\n",
    "#    ∫[0→L] (m y + b) dy = m L^2/2 + b L\n",
    "F = m*L**2/2 + b*L\n",
    "\n",
    "def calc_parameters(Eps1, Eps2, Eps6):\n",
    "        \"\"\"\n",
    "        Calculate the E and ν parameters from the strain data.\n",
    "        \"\"\"\n",
    "        # build A and B\n",
    "        A = np.zeros((2, 2))\n",
    "        B = np.zeros(2)\n",
    "\n",
    "        # Virtual field 1:  u1*=0, u2*=-x2  ⇒ ε1*=0, ε2*=-1\n",
    "        A[0, 0] = np.mean(Eps2)*L**2     \n",
    "        A[0, 1] = np.mean(Eps1)*L**2      \n",
    "        B[0]    = 0        \n",
    "\n",
    "        # Virtual field 2:  u1*=x1, u2*=0  ⇒ ε1*=1, ε2*=0\n",
    "        A[1, 0] = np.mean(Eps1)*L**2       # ∑ ε₁ sᵢ\n",
    "        A[1, 1] = np.mean(Eps2)*L**2      # ∑ ε₂ sᵢ\n",
    "        B[1]    = F * L                # ∑ σ₁ lᵢ\n",
    "\n",
    "        # solve for Q = [Q11, Q12]\n",
    "        Q11, Q12 = np.linalg.solve(A, B)\n",
    "\n",
    "        # retrieve E and ν\n",
    "        μ_id = (Q11 - Q12)/2\n",
    "        λ_id = Q12\n",
    "        Nu  = λ_id / (2*(μ_id + λ_id))\n",
    "        E  = μ_id*(3*λ_id + 2*μ_id)/(λ_id + μ_id)\n",
    "        return E, Nu\n",
    "\n",
    "prop = 0\n",
    "DIC_region = [prop*L, prop*L, (1-prop)*L, (1-prop)*L]\n",
    "\n",
    "E_list = []\n",
    "Nu_list = []\n",
    "\n",
    "for i in range(1, 20):\n",
    "        X_DIC_input, DIC_data = load_data(\"no_dataset\", 0, strain_fn, 4, 1e-6, DIC_region=DIC_region, verbose=(i==1))\n",
    "        Eps1 = DIC_data[:, 0].reshape(-1, 1)\n",
    "        Eps2 = DIC_data[:, 1].reshape(-1, 1)\n",
    "        Eps6 = DIC_data[:, 2].reshape(-1, 1)\n",
    "\n",
    "        E, Nu = calc_parameters(Eps1, Eps2, Eps6)\n",
    "        E_list.append(E)\n",
    "        Nu_list.append(Nu)\n",
    "\n",
    "E_list = np.array(E_list)\n",
    "Nu_list = np.array(Nu_list)\n",
    "print(f\"Identified:  E = {np.mean(E_list)/1e3:.4f} ± {np.std(E_list)/1e3:.4f} GPa, ν = {np.mean(Nu_list):.4f} ± {np.std(Nu_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIC grid: 114 x 115 --> Subsampled grid (including padding): 6 x 6 --> Region grid: 4 x 4\n",
      "Padding:  E = 211.3346 ± 0.1827 GPa,   ν = 0.2978 ± 0.0004\n",
      "DIC grid: 114 x 115 --> Subsampled grid: 6 x 6 --> Region grid (points used): 4 x 4\n",
      "No padding:  E = 211.7390 ± 0.1643 GPa,   ν = 0.2971 ± 0.0003\n"
     ]
    }
   ],
   "source": [
    "camera_resolution = \"2MP\"\n",
    "DIC_dataset_path = f\"2_noise_study/data_dic/{camera_resolution}/1noise\"\n",
    "prop = 0.1\n",
    "DIC_region = [prop*L, prop*L, (1-prop)*L, (1-prop)*L]\n",
    "# pad_extrapolate = True\n",
    "num_measurments = 6\n",
    "\n",
    "for pad_extrapolate in [True, False]:\n",
    "    # num_measurments = 6 if pad_extrapolate else 10\n",
    "    E_list = []\n",
    "    Nu_list = []\n",
    "    for dic_number in range(1, 11):\n",
    "        X_DIC_input, DIC_data = load_data(DIC_dataset_path, dic_number, strain_fn, num_measurments, 1e-6, DIC_region=DIC_region, pad_extrapolate=pad_extrapolate, verbose=(dic_number==1))\n",
    "\n",
    "        Eps1 = DIC_data[:, 0].reshape(-1, 1)\n",
    "        Eps2 = DIC_data[:, 1].reshape(-1, 1)\n",
    "        Eps6 = DIC_data[:, 2].reshape(-1, 1)\n",
    "\n",
    "        E, Nu = calc_parameters(Eps1, Eps2, Eps6)\n",
    "        E_list.append(E)\n",
    "        Nu_list.append(Nu)\n",
    "\n",
    "    E_list = np.array(E_list)\n",
    "    Nu_list = np.array(Nu_list)\n",
    "    padding = \"Padding:\" if pad_extrapolate else \"No padding:\"\n",
    "\n",
    "    print(f\"{padding}  E = {np.mean(E_list)/1e3:.4f} ± {np.std(E_list)/1e3:.4f} GPa,   ν = {np.mean(Nu_list):.4f} ± {np.std(Nu_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIC grid: 191 x 192 --> Subsampled grid: 191 x 191 --> Region grid (points used): 191 x 192\n",
      "DIC grid: 114 x 115 --> Subsampled grid: 114 x 114 --> Region grid (points used): 114 x 115\n",
      "DIC grid: 39 x 41 --> Subsampled grid: 39 x 39 --> Region grid (points used): 39 x 41\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Assuming load_data and calc_parameters are defined elsewhere\n",
    "# Define your variables and functions here\n",
    "\n",
    "resolutions = [\"5MP\", \"2MP\", \"0.4MP\"]\n",
    "prop = 0\n",
    "E_actual = 210.0 # Actual Young's modulus in GPa\n",
    "Nu_actual = 0.3 # Actual Poisson's ratio\n",
    "num_measurments = 1000\n",
    "\n",
    "# Load the existing JSON file\n",
    "with open(\"../2_noise_study/results/summary.json\", 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "for camera_resolution in resolutions:\n",
    "    DIC_dataset_path = f\"2_noise_study/data_dic/{camera_resolution}/1noise\"\n",
    "    DIC_region = [prop*L, prop*L, (1-prop)*L, (1-prop)*L]\n",
    "\n",
    "    E_list = []\n",
    "    Nu_list = []\n",
    "    for dic_number in range(1, 11):\n",
    "        X_DIC_input, DIC_data = load_data(DIC_dataset_path, dic_number, strain_fn, num_measurments, 1e-6, DIC_region=DIC_region, verbose=(dic_number==1))\n",
    "        Eps1 = DIC_data[:, 0].reshape(-1, 1)\n",
    "        Eps2 = DIC_data[:, 1].reshape(-1, 1)\n",
    "        Eps6 = DIC_data[:, 2].reshape(-1, 1)\n",
    "\n",
    "        E, Nu = calc_parameters(Eps1, Eps2, Eps6)\n",
    "        E_list.append(E)\n",
    "        Nu_list.append(Nu)\n",
    "\n",
    "    E_list = np.array(E_list)/1e3  # Convert to GPa\n",
    "    Nu_list = np.array(Nu_list)\n",
    "\n",
    "    json_data[camera_resolution][\"VFM\"] = {}\n",
    "\n",
    "    json_data[camera_resolution][\"VFM\"][\"E\"] = {\"mean\": np.mean(E_list), \"std\": np.std(E_list), \"mean_rel_error\": np.mean(np.abs((E_list - E_actual) / E_actual))*100, \"std_rel_error\": np.std(np.abs((E_list - E_actual) / E_actual))*100}\n",
    "    json_data[camera_resolution][\"VFM\"][\"nu\"] = {\"mean\": np.mean(Nu_list), \"std\": np.std(Nu_list), \"mean_rel_error\": np.mean(np.abs((Nu_list - Nu_actual) / Nu_actual))*100, \"std_rel_error\": np.std(np.abs((Nu_list - Nu_actual) / Nu_actual))*100}\n",
    "\n",
    "# Save the updated JSON structure back to the file\n",
    "with open(\"../2_noise_study/results/summary.json\", 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
